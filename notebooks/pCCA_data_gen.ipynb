{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some of this code is from Gregory Gundersen's pCCA repo.\n",
    "\n",
    "inv = np.linalg.inv\n",
    "\n",
    "class ProbabilisticCCA:\n",
    "    def __init__(self, n_components, n_iters, reg=1e-6):\n",
    "        \"\"\"Initialize probabilistic CCA model.\"\"\"\n",
    "        self.k = n_components\n",
    "        self.n_iters = n_iters\n",
    "        self.reg = reg  # Regularization parameter\n",
    "\n",
    "    def fit(self, X1, X2):\n",
    "        \"\"\"Fit model via EM.\"\"\"\n",
    "        self._init_params(X1, X2)\n",
    "        \n",
    "        for _ in range(self.n_iters):\n",
    "            self._em_step()\n",
    "            \n",
    "            # Add regularization to ensure PSD\n",
    "            self.Psi += self.reg * np.eye(self.Psi.shape[0])\n",
    "\n",
    "    def transform(self, X1, X2):\n",
    "        \"\"\"Embed data using fitted model.\"\"\"\n",
    "        X = np.hstack([X1, X2]).T\n",
    "        \n",
    "        # Add regularization to Psi\n",
    "        Psi_reg = self.Psi + self.reg * np.eye(self.Psi.shape[0])\n",
    "        Psi_inv = inv(Psi_reg)\n",
    "        \n",
    "        M = inv(np.eye(self.k) + self.W.T @ Psi_inv @ self.W)\n",
    "        Z = M @ self.W.T @ Psi_inv @ X\n",
    "        return Z.T\n",
    "\n",
    "    def fit_transform(self, X1, X2):\n",
    "        \"\"\"Fit and transform in one step.\"\"\"\n",
    "        self.fit(X1, X2)\n",
    "        return self.transform(X1, X2)\n",
    "\n",
    "    def sample(self, n_samples):\n",
    "        \"\"\"Sample from the fitted model.\"\"\"\n",
    "        # Add regularization to Psi\n",
    "        Psi_reg = self.Psi + self.reg * np.eye(self.Psi.shape[0])\n",
    "        Psi_inv = inv(Psi_reg)\n",
    "        \n",
    "        M = inv(np.eye(self.k) + self.W.T @ Psi_inv @ self.W)\n",
    "        Z_post_mean = M @ self.W.T @ Psi_inv @ self.X\n",
    "        X_mean = self.W @ Z_post_mean\n",
    "        \n",
    "        X = np.zeros((n_samples, self.p))\n",
    "        for i in range(n_samples):\n",
    "            # Use regularized Psi for sampling\n",
    "            X[i] = np.random.multivariate_normal(X_mean[:, i], Psi_reg)\n",
    "        \n",
    "        return X[:, :self.p1], X[:, self.p1:]\n",
    "\n",
    "    def _em_step(self):\n",
    "        \"\"\"Perform EM on parameters W and Psi\"\"\"\n",
    "        # Add regularization to Psi\n",
    "        Psi_reg = self.Psi + self.reg * np.eye(self.Psi.shape[0])\n",
    "        Psi_inv = inv(Psi_reg)\n",
    "        \n",
    "        M = inv(np.eye(self.k) + self.W.T @ Psi_inv @ self.W)\n",
    "        S = M @ self.W.T @ Psi_inv @ self.X\n",
    "        A = self.n * M + S @ S.T\n",
    "        \n",
    "        # Regularize matrix inversion\n",
    "        W_new = self.X @ S.T @ inv(A + self.reg * np.eye(A.shape[0]))\n",
    "        \n",
    "        W1 = self.W[:self.p1]\n",
    "        W1_new = W_new[:self.p1]\n",
    "        Psi1_inv = Psi_inv[:self.p1, :self.p1]\n",
    "        Psi1_new = self.Sigma1 - self.Sigma1 @ Psi1_inv @ W1 @ M @ W1_new.T\n",
    "        \n",
    "        W2 = self.W[self.p1:]\n",
    "        W2_new = W_new[self.p1:]\n",
    "        Psi2_inv = Psi_inv[self.p1:, self.p1:]\n",
    "        Psi2_new = self.Sigma2 - self.Sigma2 @ Psi2_inv @ W2 @ M @ W2_new.T\n",
    "        \n",
    "        Psi_new = np.block([[Psi1_new, np.zeros((self.p1, self.p2))],\n",
    "                             [np.zeros((self.p2, self.p1)), Psi2_new]])\n",
    "        \n",
    "        self.W = W_new\n",
    "        self.Psi = Psi_new\n",
    "\n",
    "    def _init_params(self, X1, X2):\n",
    "        \"\"\"Initialize parameters.\"\"\"\n",
    "        self.X1, self.X2 = X1, X2\n",
    "        self.n, self.p1 = self.X1.shape\n",
    "        _, self.p2 = self.X2.shape\n",
    "        self.p = self.p1 + self.p2\n",
    "        \n",
    "        # Initialize sample covariances matrices\n",
    "        self.X = np.vstack([X1, X2]).T\n",
    "        \n",
    "        # Add small regularization to covariance matrices\n",
    "        self.Sigma1 = np.cov(self.X1.T) + self.reg * np.eye(self.p1)\n",
    "        self.Sigma2 = np.cov(self.X2.T) + self.reg * np.eye(self.p2)\n",
    "        \n",
    "        # Initialize W with SVD\n",
    "        X_combined = np.hstack([X1, X2])\n",
    "        U, _, _ = np.linalg.svd(X_combined, full_matrices=False)\n",
    "        self.W = U[:, :self.k]\n",
    "        \n",
    "        # Initialize Psi with regularization\n",
    "        prior_var1 = 1\n",
    "        prior_var2 = 1\n",
    "        Psi1 = (prior_var1 + self.reg) * np.eye(self.p1)\n",
    "        Psi2 = (prior_var2 + self.reg) * np.eye(self.p2)\n",
    "        Psi = np.block([[Psi1, np.zeros((self.p1, self.p2))],\n",
    "                        [np.zeros((self.p2, self.p1)), Psi2]])\n",
    "        self.Psi = Psi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 shape: (500, 250)\n",
      "X2 shape: (600, 250)\n"
     ]
    }
   ],
   "source": [
    "# Set dimensions\n",
    "K1 = 500  # Number of observations for Group 1\n",
    "K2 = 600  # Number of observations for Group 2\n",
    "T = 250   # Number of time points\n",
    "t = np.linspace(0, 2, T)  # Time intervals\n",
    "\n",
    "# Latent dimensions\n",
    "d_s = 1   # Shared latent dimension\n",
    "d_1 = 2   # Independent latent dimension for group 1\n",
    "d_2 = 3   # Independent latent dimension for group 2\n",
    "\n",
    "# Hyperparameters\n",
    "rho = 1.0  # Scale for GP kernel\n",
    "l = 2.0    # Length scale for GP kernel\n",
    "nu = 0.1   # Noise variance for observations\n",
    "\n",
    "# Kernel function\n",
    "def rbf_kernel(t1, t2, rho=1.0, l=2.0):\n",
    "    \"\"\"RBF (Gaussian) kernel for GP\"\"\"\n",
    "    return rho * np.exp(-0.5 * ((t1[:, np.newaxis] - t2[np.newaxis, :]) / l)**2)\n",
    "\n",
    "def generate_gp_trajectories(t, n_trajectories, kernel_func, nu=0.1):\n",
    "    \"\"\"Generate GP trajectories for latent factors\"\"\"\n",
    "    K_tt = kernel_func(t, t)\n",
    "    L = np.linalg.cholesky(K_tt + nu * np.eye(len(t)))\n",
    "    trajectories = np.zeros((n_trajectories, len(t)))\n",
    "    for k in range(n_trajectories):\n",
    "        z = np.random.randn(len(t))\n",
    "        trajectories[k] = L @ z\n",
    "    return trajectories\n",
    "\n",
    "# Generate latent trajectories\n",
    "Z_shared = generate_gp_trajectories(t, d_s, rbf_kernel).T  # Shape will be (T, d_s)\n",
    "Z_1 = generate_gp_trajectories(t, d_1, rbf_kernel).T      # Shape will be (T, d_1)\n",
    "Z_2 = generate_gp_trajectories(t, d_2, rbf_kernel).T      # Shape will be (T, d_2)\n",
    "\n",
    "# Generate loading matrices\n",
    "A_s1 = np.random.randn(K1, d_s)  # Loading matrix for shared component, group 1\n",
    "A_s2 = np.random.randn(K2, d_s)  # Loading matrix for shared component, group 2\n",
    "A_1 = np.random.randn(K1, d_1)   # Loading matrix for independent component, group 1\n",
    "A_2 = np.random.randn(K2, d_2)   # Loading matrix for independent component, group 2\n",
    "\n",
    "# Generate observations\n",
    "X1 = np.zeros((K1, T))\n",
    "X2 = np.zeros((K2, T))\n",
    "\n",
    "# Generate observations for Group 1\n",
    "for i in range(K1):\n",
    "    shared_contrib = A_s1[i:i+1, :] @ Z_shared.T  # (1,d_s) @ (d_s,T) = (1,T)\n",
    "    indep_contrib = A_1[i:i+1, :] @ Z_1.T         # (1,d_1) @ (d_1,T) = (1,T)\n",
    "    X1[i] = (shared_contrib + indep_contrib).flatten()\n",
    "\n",
    "# Generate observations for Group 2\n",
    "for i in range(K2):\n",
    "    shared_contrib = A_s2[i:i+1, :] @ Z_shared.T  # (1,d_s) @ (d_s,T) = (1,T)\n",
    "    indep_contrib = A_2[i:i+1, :] @ Z_2.T         # (1,d_2) @ (d_2,T) = (1,T)\n",
    "    X2[i] = (shared_contrib + indep_contrib).flatten()\n",
    "\n",
    "# Add observation noise\n",
    "X1 += np.random.normal(0, np.sqrt(nu), X1.shape)\n",
    "X2 += np.random.normal(0, np.sqrt(nu), X2.shape)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"X1 shape:\", X1.shape)\n",
    "print(\"X2 shape:\", X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 500 and the array at index 1 has size 600",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pcca \u001b[38;5;241m=\u001b[39m ProbabilisticCCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_iters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m pcca\u001b[38;5;241m.\u001b[39mfit(X1, X2)\n\u001b[1;32m      3\u001b[0m X1_, X2_ \u001b[38;5;241m=\u001b[39m pcca\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Visualize\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 14\u001b[0m, in \u001b[0;36mProbabilisticCCA.fit\u001b[0;34m(self, X1, X2)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X1, X2):\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit model via EM.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_params(X1, X2)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iters):\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_em_step()\n",
      "Cell \u001b[0;32mIn[17], line 100\u001b[0m, in \u001b[0;36mProbabilisticCCA._init_params\u001b[0;34m(self, X1, X2)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSigma2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcov(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX2\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreg \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39meye(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp2)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Initialize W with SVD\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m X_combined \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([X1, X2])\n\u001b[1;32m    101\u001b[0m U, _, _ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msvd(X_combined, full_matrices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW \u001b[38;5;241m=\u001b[39m U[:, :\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dsc180/lib/python3.11/site-packages/numpy/core/shape_base.py:359\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 500 and the array at index 1 has size 600"
     ]
    }
   ],
   "source": [
    "pcca = ProbabilisticCCA(n_components=2, n_iters=100)\n",
    "pcca.fit(X1, X2)\n",
    "X1_, X2_ = pcca.sample(200)\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax1.scatter(X1[:, 0], X1[:, 1], label='Original Group 1')\n",
    "ax1.scatter(X2[:, 0], X2[:, 1], label='Original Group 2')\n",
    "ax1.set_title('Original Data')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.scatter(X1_[:, 0], X1_[:, 1], label='Sampled Group 1')\n",
    "ax2.scatter(X2_[:, 0], X2_[:, 1], label='Sampled Group 2')\n",
    "ax2.set_title('Sampled Data')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try using vstack instead of hstack so the dimensions line up properly\n",
    "#alternatively, input to the function the tranposes of X1 and X2\n",
    "# PIPELINE: IBL data --> vGPFA --> pCCA model\n",
    "\n",
    "\n",
    "#next: compare how well our model does against some other model\n",
    "#can also compare about some really simple models, like PCA\n",
    "#take note of what i needed to change about greg's model to fit it for out project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsc180",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9fe772517bab4a5089697f52a853ea52e9e8e9ccdfb4c27cc6b963ae540d96c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
